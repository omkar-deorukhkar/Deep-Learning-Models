{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris_Deep_Learning.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "dKrFp1pVLFgH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv'\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Urkg9l0nMxnw",
        "colab_type": "code",
        "outputId": "54ab9ade-94bc-4d3f-fabc-3bced9a68117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "\n",
        "Y = df.loc[:,'species'].values\n",
        "X = df.loc[:, 'sepal_length':'petal_width'].values\n",
        "print(Y[101:102])\n",
        "\n",
        "\n",
        "\n",
        "X = np.asarray(X)\n",
        "X = X.astype('float32')\n",
        "\n",
        "\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy='mean')\n",
        "imputer.fit(X)\n",
        "X = imputer.transform(X)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Y = Y.reshape(len(Y),1)\n",
        "\n",
        "\n",
        "OHE = OneHotEncoder()\n",
        "OHE.fit(Y)\n",
        "Y = OHE.transform(Y).toarray()\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HN47JdcGGCEC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(8,activation='relu',input_dim = 4))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(3,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CAjQ69eNHFcF",
        "colab_type": "code",
        "outputId": "648d3fee-b6bf-4f41-e4fd-c4a11cd50588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1768
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,epochs=50,batch_size=5)\n",
        "scores = model.evaluate(X_test,Y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.0539 - acc: 0.6667\n",
            "Epoch 2/50\n",
            "120/120 [==============================] - 0s 336us/step - loss: 1.0088 - acc: 0.6500\n",
            "Epoch 3/50\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.9420 - acc: 0.6500\n",
            "Epoch 4/50\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.8565 - acc: 0.6500\n",
            "Epoch 5/50\n",
            "120/120 [==============================] - 0s 360us/step - loss: 0.7554 - acc: 0.6500\n",
            "Epoch 6/50\n",
            "120/120 [==============================] - 0s 371us/step - loss: 0.6442 - acc: 0.6500\n",
            "Epoch 7/50\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.5569 - acc: 0.6500\n",
            "Epoch 8/50\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.5040 - acc: 0.7167\n",
            "Epoch 9/50\n",
            "120/120 [==============================] - 0s 382us/step - loss: 0.4695 - acc: 0.8917\n",
            "Epoch 10/50\n",
            "120/120 [==============================] - 0s 357us/step - loss: 0.4468 - acc: 0.7750\n",
            "Epoch 11/50\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.4255 - acc: 0.9250\n",
            "Epoch 12/50\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.3912 - acc: 0.9083\n",
            "Epoch 13/50\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.3624 - acc: 0.9167\n",
            "Epoch 14/50\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.3447 - acc: 0.9000\n",
            "Epoch 15/50\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.3181 - acc: 0.9000\n",
            "Epoch 16/50\n",
            "120/120 [==============================] - 0s 353us/step - loss: 0.2945 - acc: 0.9167\n",
            "Epoch 17/50\n",
            "120/120 [==============================] - 0s 377us/step - loss: 0.2958 - acc: 0.9000\n",
            "Epoch 18/50\n",
            "120/120 [==============================] - 0s 357us/step - loss: 0.2654 - acc: 0.9167\n",
            "Epoch 19/50\n",
            "120/120 [==============================] - 0s 358us/step - loss: 0.2551 - acc: 0.9250\n",
            "Epoch 20/50\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.2385 - acc: 0.9250\n",
            "Epoch 21/50\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.2208 - acc: 0.9083\n",
            "Epoch 22/50\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.2104 - acc: 0.9333\n",
            "Epoch 23/50\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.2073 - acc: 0.9250\n",
            "Epoch 24/50\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.1958 - acc: 0.8917\n",
            "Epoch 25/50\n",
            "120/120 [==============================] - 0s 278us/step - loss: 0.1829 - acc: 0.9500\n",
            "Epoch 26/50\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.1670 - acc: 0.9417\n",
            "Epoch 27/50\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.1943 - acc: 0.9417\n",
            "Epoch 28/50\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.1919 - acc: 0.9167\n",
            "Epoch 29/50\n",
            "120/120 [==============================] - 0s 285us/step - loss: 0.1744 - acc: 0.9333\n",
            "Epoch 30/50\n",
            "120/120 [==============================] - 0s 276us/step - loss: 0.1619 - acc: 0.9500\n",
            "Epoch 31/50\n",
            "120/120 [==============================] - 0s 292us/step - loss: 0.1478 - acc: 0.9333\n",
            "Epoch 32/50\n",
            "120/120 [==============================] - 0s 251us/step - loss: 0.1589 - acc: 0.9250\n",
            "Epoch 33/50\n",
            "120/120 [==============================] - 0s 264us/step - loss: 0.1387 - acc: 0.9417\n",
            "Epoch 34/50\n",
            "120/120 [==============================] - 0s 268us/step - loss: 0.1375 - acc: 0.9417\n",
            "Epoch 35/50\n",
            "120/120 [==============================] - 0s 266us/step - loss: 0.1340 - acc: 0.9333\n",
            "Epoch 36/50\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.1326 - acc: 0.9500\n",
            "Epoch 37/50\n",
            "120/120 [==============================] - 0s 278us/step - loss: 0.1282 - acc: 0.9333\n",
            "Epoch 38/50\n",
            "120/120 [==============================] - 0s 289us/step - loss: 0.1286 - acc: 0.9500\n",
            "Epoch 39/50\n",
            "120/120 [==============================] - 0s 282us/step - loss: 0.1204 - acc: 0.9583\n",
            "Epoch 40/50\n",
            "120/120 [==============================] - 0s 285us/step - loss: 0.1187 - acc: 0.9333\n",
            "Epoch 41/50\n",
            "120/120 [==============================] - 0s 278us/step - loss: 0.1131 - acc: 0.9667\n",
            "Epoch 42/50\n",
            "120/120 [==============================] - 0s 281us/step - loss: 0.1308 - acc: 0.9500\n",
            "Epoch 43/50\n",
            "120/120 [==============================] - 0s 286us/step - loss: 0.1149 - acc: 0.9500\n",
            "Epoch 44/50\n",
            "120/120 [==============================] - 0s 292us/step - loss: 0.1162 - acc: 0.9333\n",
            "Epoch 45/50\n",
            "120/120 [==============================] - 0s 287us/step - loss: 0.1088 - acc: 0.9583\n",
            "Epoch 46/50\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.1112 - acc: 0.9500\n",
            "Epoch 47/50\n",
            "120/120 [==============================] - 0s 274us/step - loss: 0.1130 - acc: 0.9583\n",
            "Epoch 48/50\n",
            "120/120 [==============================] - 0s 268us/step - loss: 0.1049 - acc: 0.9417\n",
            "Epoch 49/50\n",
            "120/120 [==============================] - 0s 269us/step - loss: 0.1089 - acc: 0.9583\n",
            "Epoch 50/50\n",
            "120/120 [==============================] - 0s 260us/step - loss: 0.1025 - acc: 0.9500\n",
            "30/30 [==============================] - 0s 6ms/step\n",
            "\n",
            "acc: 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ncZ7y7MQHbYX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "w-9tSL2_Kriu",
        "colab_type": "code",
        "outputId": "10931290-79a0-44fc-d73a-c85a83458ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "H = model.predict_classes(X_test[:10])\n",
        "\n",
        "classes ={0:'setosa',1:'versicolor',2:'virginica'}\n",
        "for i in H:\n",
        "  print(classes[i])\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "versicolor\n",
            "setosa\n",
            "setosa\n",
            "versicolor\n",
            "setosa\n",
            "versicolor\n",
            "setosa\n",
            "virginica\n",
            "virginica\n",
            "virginica\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}